{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.995429151853733,
  "eval_steps": 100,
  "global_step": 4920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1015744032503809,
      "grad_norm": 0.20465943217277527,
      "learning_rate": 2.0121951219512197e-05,
      "loss": 3.8081,
      "step": 100
    },
    {
      "epoch": 0.2031488065007618,
      "grad_norm": 0.18299134075641632,
      "learning_rate": 4.044715447154472e-05,
      "loss": 3.5433,
      "step": 200
    },
    {
      "epoch": 0.3047232097511427,
      "grad_norm": 0.1856904923915863,
      "learning_rate": 4.9984138722876964e-05,
      "loss": 3.397,
      "step": 300
    },
    {
      "epoch": 0.4062976130015236,
      "grad_norm": 0.23603034019470215,
      "learning_rate": 4.9867921409295605e-05,
      "loss": 3.3264,
      "step": 400
    },
    {
      "epoch": 0.5078720162519045,
      "grad_norm": 0.24515867233276367,
      "learning_rate": 4.9639399298903224e-05,
      "loss": 3.3149,
      "step": 500
    },
    {
      "epoch": 0.6094464195022854,
      "grad_norm": 0.25027599930763245,
      "learning_rate": 4.929960440916328e-05,
      "loss": 3.2901,
      "step": 600
    },
    {
      "epoch": 0.7110208227526663,
      "grad_norm": 0.24943634867668152,
      "learning_rate": 4.885007127106538e-05,
      "loss": 3.2718,
      "step": 700
    },
    {
      "epoch": 0.8125952260030472,
      "grad_norm": 0.2547142803668976,
      "learning_rate": 4.829282999910535e-05,
      "loss": 3.2712,
      "step": 800
    },
    {
      "epoch": 0.9141696292534282,
      "grad_norm": 0.2711445987224579,
      "learning_rate": 4.763039712318498e-05,
      "loss": 3.2648,
      "step": 900
    },
    {
      "epoch": 1.015236160487557,
      "grad_norm": 0.2603870928287506,
      "learning_rate": 4.6865764223835154e-05,
      "loss": 3.2586,
      "step": 1000
    },
    {
      "epoch": 1.116810563737938,
      "grad_norm": 0.27402928471565247,
      "learning_rate": 4.6002384422086074e-05,
      "loss": 3.2385,
      "step": 1100
    },
    {
      "epoch": 1.2183849669883189,
      "grad_norm": 0.27738258242607117,
      "learning_rate": 4.5044156784997316e-05,
      "loss": 3.2466,
      "step": 1200
    },
    {
      "epoch": 1.3199593702386998,
      "grad_norm": 0.2777794897556305,
      "learning_rate": 4.3995408717272715e-05,
      "loss": 3.2339,
      "step": 1300
    },
    {
      "epoch": 1.4215337734890807,
      "grad_norm": 0.27824196219444275,
      "learning_rate": 4.2860876418480926e-05,
      "loss": 3.2604,
      "step": 1400
    },
    {
      "epoch": 1.5231081767394616,
      "grad_norm": 0.2831946015357971,
      "learning_rate": 4.164568349413743e-05,
      "loss": 3.2343,
      "step": 1500
    },
    {
      "epoch": 1.6246825799898426,
      "grad_norm": 0.2851007282733917,
      "learning_rate": 4.03553178172417e-05,
      "loss": 3.2606,
      "step": 1600
    },
    {
      "epoch": 1.7262569832402235,
      "grad_norm": 0.28345704078674316,
      "learning_rate": 3.899560674476378e-05,
      "loss": 3.2386,
      "step": 1700
    },
    {
      "epoch": 1.8278313864906044,
      "grad_norm": 0.26885896921157837,
      "learning_rate": 3.757269080100419e-05,
      "loss": 3.2286,
      "step": 1800
    },
    {
      "epoch": 1.9294057897409853,
      "grad_norm": 0.2707153856754303,
      "learning_rate": 3.6092995946673994e-05,
      "loss": 3.2325,
      "step": 1900
    },
    {
      "epoch": 2.030472320975114,
      "grad_norm": 0.3220553398132324,
      "learning_rate": 3.456320455892984e-05,
      "loss": 3.2307,
      "step": 2000
    },
    {
      "epoch": 2.132046724225495,
      "grad_norm": 0.2759985327720642,
      "learning_rate": 3.299022525341901e-05,
      "loss": 3.2166,
      "step": 2100
    },
    {
      "epoch": 2.233621127475876,
      "grad_norm": 0.29212936758995056,
      "learning_rate": 3.138116168462012e-05,
      "loss": 3.2352,
      "step": 2200
    },
    {
      "epoch": 2.335195530726257,
      "grad_norm": 0.283559113740921,
      "learning_rate": 2.9743280465378538e-05,
      "loss": 3.2239,
      "step": 2300
    },
    {
      "epoch": 2.4367699339766378,
      "grad_norm": 0.2780139148235321,
      "learning_rate": 2.8083978350513452e-05,
      "loss": 3.2163,
      "step": 2400
    },
    {
      "epoch": 2.5383443372270187,
      "grad_norm": 0.28341513872146606,
      "learning_rate": 2.6410748832697252e-05,
      "loss": 3.2196,
      "step": 2500
    },
    {
      "epoch": 2.6399187404773996,
      "grad_norm": 0.2818538546562195,
      "learning_rate": 2.47311483014618e-05,
      "loss": 3.2177,
      "step": 2600
    },
    {
      "epoch": 2.7414931437277805,
      "grad_norm": 0.30732131004333496,
      "learning_rate": 2.3052761918159314e-05,
      "loss": 3.2245,
      "step": 2700
    },
    {
      "epoch": 2.8430675469781614,
      "grad_norm": 0.28283363580703735,
      "learning_rate": 2.13831693609883e-05,
      "loss": 3.2139,
      "step": 2800
    },
    {
      "epoch": 2.9446419502285424,
      "grad_norm": 0.28127002716064453,
      "learning_rate": 1.9729910594781494e-05,
      "loss": 3.2059,
      "step": 2900
    },
    {
      "epoch": 3.0457084814626714,
      "grad_norm": 0.2942373752593994,
      "learning_rate": 1.8100451820141633e-05,
      "loss": 3.2081,
      "step": 3000
    },
    {
      "epoch": 3.1472828847130523,
      "grad_norm": 0.29194653034210205,
      "learning_rate": 1.6502151755700114e-05,
      "loss": 3.2143,
      "step": 3100
    },
    {
      "epoch": 3.248857287963433,
      "grad_norm": 0.270545095205307,
      "learning_rate": 1.4942228405769597e-05,
      "loss": 3.2123,
      "step": 3200
    },
    {
      "epoch": 3.350431691213814,
      "grad_norm": 0.2822510898113251,
      "learning_rate": 1.3427726463469877e-05,
      "loss": 3.2097,
      "step": 3300
    },
    {
      "epoch": 3.452006094464195,
      "grad_norm": 0.2891305983066559,
      "learning_rate": 1.1965485496535614e-05,
      "loss": 3.1971,
      "step": 3400
    },
    {
      "epoch": 3.553580497714576,
      "grad_norm": 0.2752155363559723,
      "learning_rate": 1.0562109059480988e-05,
      "loss": 3.2132,
      "step": 3500
    },
    {
      "epoch": 3.655154900964957,
      "grad_norm": 0.2818962037563324,
      "learning_rate": 9.22393487161189e-06,
      "loss": 3.2273,
      "step": 3600
    },
    {
      "epoch": 3.756729304215338,
      "grad_norm": 0.28161919116973877,
      "learning_rate": 7.957006195563434e-06,
      "loss": 3.2041,
      "step": 3700
    },
    {
      "epoch": 3.8583037074657187,
      "grad_norm": 0.29669591784477234,
      "learning_rate": 6.767044545618878e-06,
      "loss": 3.2086,
      "step": 3800
    },
    {
      "epoch": 3.9598781107160996,
      "grad_norm": 0.3101819157600403,
      "learning_rate": 5.659423849060288e-06,
      "loss": 3.205,
      "step": 3900
    },
    {
      "epoch": 4.060944641950228,
      "grad_norm": 0.2936779260635376,
      "learning_rate": 4.6391461772398944e-06,
      "loss": 3.2093,
      "step": 4000
    },
    {
      "epoch": 4.162519045200609,
      "grad_norm": 0.2922394275665283,
      "learning_rate": 3.7108191559716288e-06,
      "loss": 3.2055,
      "step": 4100
    },
    {
      "epoch": 4.26409344845099,
      "grad_norm": 0.3112284541130066,
      "learning_rate": 2.8786351572588437e-06,
      "loss": 3.1921,
      "step": 4200
    },
    {
      "epoch": 4.365667851701371,
      "grad_norm": 0.2867610454559326,
      "learning_rate": 2.146352366329274e-06,
      "loss": 3.2179,
      "step": 4300
    },
    {
      "epoch": 4.467242254951752,
      "grad_norm": 0.2754484713077545,
      "learning_rate": 1.5172778094795586e-06,
      "loss": 3.2243,
      "step": 4400
    },
    {
      "epoch": 4.568816658202133,
      "grad_norm": 0.2831850051879883,
      "learning_rate": 9.94252419376465e-07,
      "loss": 3.1999,
      "step": 4500
    },
    {
      "epoch": 4.670391061452514,
      "grad_norm": 0.2922910749912262,
      "learning_rate": 5.796382052605575e-07,
      "loss": 3.2146,
      "step": 4600
    },
    {
      "epoch": 4.771965464702895,
      "grad_norm": 0.2817777097225189,
      "learning_rate": 2.7530758599246254e-07,
      "loss": 3.2025,
      "step": 4700
    },
    {
      "epoch": 4.8735398679532755,
      "grad_norm": 0.2885815501213074,
      "learning_rate": 8.263493411412582e-08,
      "loss": 3.206,
      "step": 4800
    },
    {
      "epoch": 4.9751142712036565,
      "grad_norm": 0.28956690430641174,
      "learning_rate": 2.4903691125788277e-09,
      "loss": 3.1964,
      "step": 4900
    }
  ],
  "logging_steps": 100,
  "max_steps": 4920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4919306986913792e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
